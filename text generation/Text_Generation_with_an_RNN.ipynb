{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation with an RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/deep-nlp/blob/master/text%20generation/Text_Generation_with_an_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlXYTQSmKsdf",
        "colab_type": "code",
        "outputId": "2a6ebbd7-65f5-43ab-ff55-d6b05ca9c8d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, print_function, unicode_literals, absolute_import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfDV-_zRq1Zi",
        "colab_type": "code",
        "outputId": "e8e2813d-a78e-42be-fc45-e21837ce99bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JauRNGVaz8kJ",
        "colab_type": "code",
        "outputId": "3e29f00c-0898-42ec-aba1-ca324890ea11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFckfKAYVt9A",
        "colab_type": "code",
        "outputId": "89af9ae3-26df-4750-ebfd-2056576b3651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43IIQKzOVzj9",
        "colab_type": "code",
        "outputId": "2ffff503-a9a9-4177-b537-f13de08176b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print('{} unique characters.'.format(len(vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 unique characters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62J12YuBV9Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmukF-UTWrvl",
        "colab_type": "code",
        "outputId": "ac891afb-7033-4230-bee7-c70c0d4c5625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print(\"{\")\n",
        "for char, _ in zip(char2idx, range(20)):\n",
        "  print(' {:4s}: {:3d}, '.format(repr(char), char2idx[char]))\n",
        "print('   ...\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            " '\\n':   0, \n",
            " ' ' :   1, \n",
            " '!' :   2, \n",
            " '$' :   3, \n",
            " '&' :   4, \n",
            " \"'\" :   5, \n",
            " ',' :   6, \n",
            " '-' :   7, \n",
            " '.' :   8, \n",
            " '3' :   9, \n",
            " ':' :  10, \n",
            " ';' :  11, \n",
            " '?' :  12, \n",
            " 'A' :  13, \n",
            " 'B' :  14, \n",
            " 'C' :  15, \n",
            " 'D' :  16, \n",
            " 'E' :  17, \n",
            " 'F' :  18, \n",
            " 'G' :  19, \n",
            "   ...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-LXjO_b_ESz",
        "colab_type": "code",
        "outputId": "b0409bf3-0d84-4ebe-ce72-ea0e9670d9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(f'{repr(text[:15])} ------ characters mapped to int ------------> {text_as_int[:15]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\n' ------ characters mapped to int ------------> [18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQFj9Vmo_USn",
        "colab_type": "text"
      },
      "source": [
        "### The prediction task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITCQD0wp_f1c",
        "colab_type": "text"
      },
      "source": [
        "Given a character, or a sequence of characters, what is the most probable next character? This is the task we're training the model to perform. The input to the model will be a sequence of characters, and we train the model to predict the outputâ€”the following character at each time step.\n",
        "\n",
        "Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed until this moment, what is the next character?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt-0U_e5_jXE",
        "colab_type": "text"
      },
      "source": [
        "### Create training examples and targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcsPhghp_oLu",
        "colab_type": "text"
      },
      "source": [
        "Next divide the text into example sequences. Each input sequence will contain seq_length characters from the text.\n",
        "\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of seq_length+1. For example, say seq_length is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
        "\n",
        "To do this first use the tf.data.Dataset.from_tensor_slices function to convert the text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQfZbeLfAGZI",
        "colab_type": "code",
        "outputId": "cd2e965d-9a92-44ea-fe0f-e132cca60830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "seq_length = 100\n",
        "\n",
        "examples_per_epoch = len(text)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(10):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j04PcZqgAYkY",
        "colab_type": "code",
        "outputId": "531a7476-e551-4fe9-c5d2-ca9dfb2d38e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(''.join(idx2char[item.numpy()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n",
            "now Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us ki\n",
            "ll him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be d\n",
            "one: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeXx-LmUAqYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXg8DkEuBEqP",
        "colab_type": "code",
        "outputId": "1cda486d-d6ce-4e72-ac3c-e8e2270433b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print('Target data: ',repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data:  'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaqDTlWRBdzR",
        "colab_type": "code",
        "outputId": "2ba96c6a-f93c-49c1-8ed1-de241a96b00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "  print(\"Step: {:4d}\".format(i))\n",
        "  print(\" input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "  print(\" target: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step:    0\n",
            " input: 18 ('F')\n",
            " target: 47 ('i')\n",
            "Step:    1\n",
            " input: 47 ('i')\n",
            " target: 56 ('r')\n",
            "Step:    2\n",
            " input: 56 ('r')\n",
            " target: 57 ('s')\n",
            "Step:    3\n",
            " input: 57 ('s')\n",
            " target: 58 ('t')\n",
            "Step:    4\n",
            " input: 58 ('t')\n",
            " target: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMGIMhFnCDr5",
        "colab_type": "code",
        "outputId": "6e947fc5-b389-431a-c258-7ddd0bdf6479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset.element_spec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KujPjQ1WHbcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KscWxsdHf6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "                               tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "                               tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "                              #  tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform')),\n",
        "                              #  tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform')),\n",
        "                               tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRGd58psIeGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size=len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDP0NUPSIoBg",
        "colab_type": "code",
        "outputId": "0b5c0b3c-41c3-433b-94b6-7fcd14f5b00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 10,319,169\n",
            "Trainable params: 10,319,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGdTN1rhIqG0",
        "colab_type": "code",
        "outputId": "7d5d3be7-aa7d-4e5a-c2eb-ae941c43007e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# batch_size, sequence_length, vocab_size\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # batch_size, sequence_length, vocab_size\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PjS4sucJGWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npj-JSkfVaQb",
        "colab_type": "text"
      },
      "source": [
        "To get actual predictions from the model we need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary.\n",
        "\n",
        "**Note: It is important to sample from this distribution as taking the argmax of the distribution can easily get the model stuck in a loop.**c\n",
        "\n",
        "Try it for the first example in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh3vQlGJUXRa",
        "colab_type": "code",
        "outputId": "c5ba773f-444a-4af9-d67b-96c01383fe3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print('Input: \\n', repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\",repr(\"\".join(idx2char[sampled_indices])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'it.\\n\\nSecond Gentleman:\\nWhat, pray you, became of Antigonus, that carried\\nhence the child?\\n\\nThird Gen'\n",
            "\n",
            "Next Char Predictions: \n",
            " \"iFyl.o\\ngEyUM:T';V fVeIbmhZQL\\nasQgpV mn'pGfK!CNfmgUAcSJF$3C?xMmi:t,mred\\nm$TaHuNpAsnUp?mifaGpGbhDs'zOX\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4u_oM0AVEhJ",
        "colab_type": "code",
        "outputId": "3baf9147-388a-4e9d-867c-28bfb96172f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Predictions shape: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Scalar loss: \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions shape:  (64, 100, 65) # (batch_size, sequence_length, vocab_size)\n",
            "Scalar loss:  4.1737604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3ryOgaCWnnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqYXaVi1XMx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mti4--7oXTE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXLZsclGXVfs",
        "colab_type": "code",
        "outputId": "52c777d7-39ab-4be4-9c86-d2de099e35d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 172 steps\n",
            "Epoch 1/30\n",
            "172/172 [==============================] - 19s 109ms/step - loss: 2.6462\n",
            "Epoch 2/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 1.8416\n",
            "Epoch 3/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 1.5764\n",
            "Epoch 4/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 1.4541\n",
            "Epoch 5/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 1.3831\n",
            "Epoch 6/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 1.3295\n",
            "Epoch 7/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 1.2830\n",
            "Epoch 8/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 1.2381\n",
            "Epoch 9/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 1.1937\n",
            "Epoch 10/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 1.1446\n",
            "Epoch 11/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 1.0927\n",
            "Epoch 12/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 1.0378\n",
            "Epoch 13/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.9784\n",
            "Epoch 14/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.9177\n",
            "Epoch 15/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 0.8554\n",
            "Epoch 16/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.7966\n",
            "Epoch 17/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.7415\n",
            "Epoch 18/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.6917\n",
            "Epoch 19/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.6485\n",
            "Epoch 20/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.6088\n",
            "Epoch 21/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 0.5743\n",
            "Epoch 22/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.5476\n",
            "Epoch 23/30\n",
            "172/172 [==============================] - 17s 99ms/step - loss: 0.5217\n",
            "Epoch 24/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.5013\n",
            "Epoch 25/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.4853\n",
            "Epoch 26/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.4715\n",
            "Epoch 27/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.4574\n",
            "Epoch 28/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.4482\n",
            "Epoch 29/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.4394\n",
            "Epoch 30/30\n",
            "172/172 [==============================] - 17s 100ms/step - loss: 0.4326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_VG7FKHXc3N",
        "colab_type": "code",
        "outputId": "1a473264-1f28-403f-9ac2-810698040f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://github.com/Skuldur/Classical-Piano-Composer\n",
        "\n",
        "tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMD4PakLCe3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size=vocab_size, embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-PcdxWgC5dX",
        "colab_type": "code",
        "outputId": "856f083a-7216-4209-a648-64b61fb5e42d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 1024)           6297600   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 10,319,169\n",
            "Trainable params: 10,319,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zq22ktRDCwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generate = 10000\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  temperature = 1.0\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_GZRXypbeOt",
        "colab_type": "code",
        "outputId": "b051ff79-dd5b-46d7-a124-3b97256b9370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(generate_text(model, start_string='RAGINI: '))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAGINI: I am out of saint, Vomand;\n",
            "What lovely years? and do your person prince\n",
            "Even witless but the bow of Times,\n",
            "Reguiment easher write of sense.\n",
            "That I would r for't hat slept no more: I am like no season'd by the interrupted waters,\n",
            "To draw with idle spiders' services\n",
            "You do limbund waves by sulmnds:\n",
            "But little thing to fall process of my tongue.\n",
            "\n",
            "LADY ANNE:\n",
            "I would I knew thy heart's great beauty in her absence\n",
            "But dull all ready at the threshold\n",
            "Will have just out.\n",
            "\n",
            "CORIOLANUS:\n",
            "Tush, tush!\n",
            "\n",
            "MENENIUS:\n",
            "What would you have, fright im my true love's hand,\n",
            "Laugh and dispersed by tears in Romeo!\n",
            "\n",
            "ROMEO:\n",
            "I stretch it out fetch my lips, Arch, safely did swill be my will\n",
            "I keep the law,\n",
            "Now purses, Seeking and harrow in heaven blest in no kind with blood,\n",
            "Were but a foil of York; and I can leave you to your forwardish'd, put up the squay of holy oath?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "He cannot be most welcome! A mabest, I have death\n",
            "stabb'd my Edward's grave, lords and watchful gentle king,\n",
            "And adventure stood, and he and I\n",
            "Will watch thy waking right hat, wreck'd, and scorn'd a fevel of thy charge?\n",
            "Heavy vort, I warrant, authority be a wiveable.\n",
            "Ravely loath-dake earth, my son Lucentio.\n",
            "\n",
            "ROMEO:\n",
            "Ay, MERCUTIO:\n",
            "'Tis not like to it. Haw he died on her, sir?\n",
            "This is a garlirs do a planet, go and entreat\n",
            "Julicians upon her, though I tear you\n",
            "Held out the mirth o' the feast. Are well they call thee mountenance.\n",
            "But you shall use the people wept, or else\n",
            "two ears the thirsty each on dis\n",
            "Cut off a bardon'd by their witchcraft thus my love.\n",
            "O, you are novices! 'tis a world lose.\n",
            "First with a broken out all with rude that\n",
            "Hath stood more proid, son Petruchio!\n",
            "A bawd you more to command a head-or boar!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I'll hear no more business. Ifay believe me so,\n",
            "My other service is repedience.\n",
            "There's thy const best murderer:\n",
            "Now I williut i' the right, gainsadll impute lior devise.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Here is a worser man.\n",
            "A bawd of lamentations of the witness,\n",
            "Of the father will I come to you at enmity\n",
            "With city topethersour lives by raged\n",
            "Her inhat is not Romeo call'd,\n",
            "Let us alone to guard What with loathet be interchange of service,\n",
            "Our tribunes. ASTIAN:\n",
            "What airy wife.\n",
            "\n",
            "VIRGILIA:\n",
            "Good my letters, yet thy lips keep my stay was not a subject.\n",
            "\n",
            "KING RICHARD III:\n",
            "False to the queen: let us not.\n",
            "Welcome, Sir John! But why call home,\n",
            "Good legs and Tybalt began to bear?\n",
            "Makes him so well acknowledged you\n",
            "out, alas!\n",
            "We bodged again; and let him sirrant with his hands.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Was never widow had He dires dead?\n",
            "The queen you'ld what I am a gentleman so unluchious, and their\n",
            "ckeet Henour; farewell, and sings as nightingale:\n",
            "Say that she wrought you,--for these yellows of the death,\n",
            "But my hand helce; Coriolanus\n",
            "Hath yido sorrow so much!\n",
            "To do this deed, did very meaner magistrar most contemption.\n",
            "\n",
            "DUKE OF YORK:\n",
            "Who do nothing but heavy we?\n",
            "He shall not make my audit gut to the sun.\n",
            "I'll in any fair A:\n",
            "So did I; for the dearth, I tell thee, homicide,\n",
            "The time may keep this curse against you.\n",
            "\n",
            "CORIOLANUS:\n",
            "The sister Bona, that first in baund lest his his oath and hands with holy absence!\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Ay me, I see these honest peaceful steps?\n",
            "If we past hear you, if you please,\n",
            "To be full like me: yet they must be feast, for this woo certain as you are.\n",
            "What is the matter, you would lay on me,\n",
            "That valiant heat out the revels and\n",
            "extraction: but we enother, but the last,\n",
            "Dispatch it presently.' No, nor your manors\n",
            "Make us past else; for Virgety,\n",
            "With all your just charge honour's place.\n",
            "\n",
            "First Petruchio; stay, you are the citizens,\n",
            "Or lowly knows. Where is my Romeo?\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "Hold out my horse, and I know our noralls must excuse.\n",
            "\n",
            "GLOUCESTER:\n",
            "But you have been so stept and gelded o'erwerentlemanks their stirma's dead,\n",
            "and make their peace what you have let'st fly: but were you to say\n",
            "But with a sigh: of ceremony, if they\n",
            "Stay discover the contrary.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Hars him.\n",
            "\n",
            "BRUTUS:\n",
            "You'll succor him!\n",
            "\n",
            "ROMEO:\n",
            "Ay, but not lies the man that I stand as\n",
            "and gall back'd with practise with a ll justice, which shall remain\n",
            "That when he was wonted\n",
            "That I should know what will.\n",
            "I could dead to have his hands refused, or thee.\n",
            "\n",
            "Nurse:\n",
            "Now, by my sexitherY citizen thee,\n",
            "That either victory, or else a groom'd help,\n",
            "Our subjects' name!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "As now you not the fair Rosaline would make him like a sea,\n",
            "And in the belly service which that it so hotly either, now\n",
            "That would divorce thy envious manacles that be.\n",
            "Here comes a gentler thunder there changed\n",
            "colour; strong and good but still again,\n",
            "Ere he a man direct agreeen with knaves in God, 'tis that he hath suffer me\n",
            "The earldom of Hereford, and the laws\n",
            "That unsubstant thy fault through my purpose.\n",
            "\n",
            "ISABELLA:\n",
            "And look the love of heaven; he, little posts\n",
            "For so gree jest with him and him to-day?\n",
            "Rive me stir a willingly obey you did lack them Juliet.\n",
            "\n",
            "ROMEO:\n",
            "With lieutenant.\n",
            "\n",
            "MIRANDA:\n",
            "But the bewerds make thee pretty death,\n",
            "I cannot judge: but to conclude with truth, Verona, let them hence away,\n",
            "Be so; and first begin with her the casers,\n",
            "Aliverb'd them to a king, proud queen, and young and sight,\n",
            "To live with Tranio minst me well,\n",
            "They'll strive, with trouble thou must die:\n",
            "And, seeking daughter, now t came to us, that the queen\n",
            "Hath in the vault have crab.\n",
            "\n",
            "ROMEO:\n",
            "Ay, Richard, what a fault would he were slaid,\n",
            "He thresenved the maid I married; neither good mother,\n",
            "He straight disguised here,\n",
            "A volumeak.\n",
            "\n",
            "MARIANA:\n",
            "Isabel.\n",
            "\n",
            "ISABELLA:\n",
            "As much to hear of him.\n",
            "\n",
            "GONZALO:\n",
            "Nay, good, be patient.\n",
            "\n",
            "Boatswain:\n",
            "Whereof desperate, sir?\n",
            "\n",
            "AUTOLYCUS:\n",
            "No, good madam;' pass'd the napkin bears:\n",
            "A virging and by the tribunes, we can be piece\n",
            "For our assurance groud, to prove you in his sacredy helds,\n",
            "Through at the casple so unprovided.\n",
            "Fie, doth be held by circumms,\n",
            "And water can what ease this earth of majesty; and first were so contented.\n",
            "\n",
            "KING RICHARD III:\n",
            "My father's efest in being one of fourteen years,\n",
            "Patting both their friends, sir, the bearing\n",
            "Of Berumation setter'd ill they lack of steet, discover this is honest wife,\n",
            "The better for 'em.\n",
            "\n",
            "MENENIUS:\n",
            "What would you have pray'd?\n",
            "\n",
            "VOLUMNIA:\n",
            "Ha, thus and heaven, and let him let me have\n",
            "The fresh propation read o' the lamble:\n",
            "Unever was survey, to Burguish it, if you will in,\n",
            "But only seem sound,\n",
            "Whereto I have cause to you no unproper Burgant,\n",
            "When he has put up of heaven, though reason\n",
            "From slaughter, and then they dropp'st thee here.\n",
            "This Edward will I live to say, a moizen:\n",
            "His name! let us that burn is true.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Tell me thine faill\n",
            "To save at least the heies of her own.\n",
            "\n",
            "CLARENCE:\n",
            "Let and did fight with us.\n",
            "\n",
            "CLARENCE:\n",
            "With thou art out the people!\n",
            "\n",
            "SICKs heart of late hasty,\n",
            "The loss o' the seat of manhood thou, boy,\n",
            "poor king of that, I trust I thene be laid off false and reside the melting bid them break it out a\n",
            "good day's work, and hold thy palm world paper ready?\n",
            "\n",
            "RICHARD:\n",
            "I cannot judge: but to conclude with triumph death,\n",
            "Or else be king, or die, first.\n",
            "\n",
            "TRANIO:\n",
            "'Tis some odd humour pricks him to the Tower.\n",
            "\n",
            "GLOUCESTER:\n",
            "But for his body hold in him:\n",
            "He loves a way to kindly heart.\n",
            "\n",
            "Nurse:\n",
            "Alasurs away.\n",
            "\n",
            "SAMPSON:\n",
            "Draw, if you be wicked vicause most faults.\n",
            "\n",
            "ELBOW:\n",
            "If it? plain amazed:\n",
            "Good early in a looker-own\n",
            "brother: 'Ay,' quoth my uncle Abhard's life,\n",
            "That this way to endure from the ground.\n",
            "\n",
            "SLY:\n",
            "I am are your worships. Barce, or winto say: but look thee here,\n",
            "And then deny had found him to the block.\n",
            "\n",
            "PROSPERO:\n",
            "Brother, one word were cordial.\n",
            "\n",
            "CAMILLO:\n",
            "Sir, my lord,\n",
            "I could believe but as thou wilt confess your own.\n",
            "\n",
            "CAMILLO:\n",
            "\n",
            "First Servingman:\n",
            "Nay, it's no matter for the deputy?\n",
            "\n",
            "MENENIUS:\n",
            "Take my capa, my rapier, bon.\n",
            "\n",
            "MENENIUS:\n",
            "O, he's a lightning before dead by the worst.\n",
            "\n",
            "PETRUCHIO:\n",
            "Ay, there's the queen's are o' the lamb! why comest thou? which of you all your delivery?\n",
            "\n",
            "LADY CAPULET:\n",
            "A fortnight and odd days know it.\n",
            "\n",
            "ROMEO:\n",
            "A tormore fortune, step as here and 't:\n",
            "Wilt thou be safe? see, twelve weeke you with discourses in the stars\n",
            "Shall bitterly begin his fearful arms and the ground.\n",
            "\n",
            "Shepherd:\n",
            "His wife, a man's cotters.\n",
            "\n",
            "LADY ANNE:\n",
            "I would fain be bold to say: but give him good friend.\n",
            "\n",
            "HERMIONE:\n",
            "'Tis pity\n",
            "To set the consuls and dreams;\n",
            "Which common life.\n",
            "\n",
            "A good discretio.\n",
            "\n",
            "BAPTISTA:\n",
            "Gentle my liege,--a marquess.\n",
            "\n",
            "DORSET:\n",
            "I would thou art the might have been consul, let them\n",
            "Renowned village brought my lips,\n",
            "Each part, yet was on him suffer me. Here, close with him!\n",
            "\n",
            "Send her se:\n",
            "But the rare beats here in a parloum behind, to\n",
            "crupp her ignorance,\n",
            "And their stern me or seest, stand all aloof,\n",
            "And do not interray'd to fall\n",
            "By the day proling disposition,\n",
            "But fear the conquerors; I'll begin him in.\n",
            "\n",
            "All Conspirators:\n",
            "King Lewis and Lancaster?\n",
            "But come, my lord, and leave us their sufficier down to heart.\n",
            "As I did say, the duke? never stay with me too late?\n",
            "\n",
            "LORD FITZWATER:\n",
            "Humbly you, if you hand any thing, as never\n",
            "I mean the hate of those lands and\n",
            "The fraughtip in The watery star call him.\n",
            "You are to do much rein to you,\n",
            "As one whom they have lost me from the day,\n",
            "Whether you can show so?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Why, young thou art we;' the lark,\n",
            "Because his fathers shall be protector?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "O thou well skined, bese counsellors by natures yet\n",
            "You may defital busy!\n",
            "\n",
            "SICINIUS:\n",
            "Where is this viper\n",
            "That would depart with heaven and to you; I will never more\n",
            "have ta'en yone's best friend.\n",
            "\n",
            "ALOLO:\n",
            "He that will sweet as spring him haply she\n",
            "will I do see the end of their sovereigns;\n",
            "But if all see noors live.\n",
            "Have I here, ho! fould have been much better it were my conserves your idle wounds the white o'eranchusby\n",
            "This isle, there in the night hath for my head\n",
            "And this small grief and strength could equal them.\n",
            "Well, say you such a on word horse urpened:\n",
            "A boon of vistress barver, when it be,\n",
            "I cannot buy him.\n",
            "\n",
            "CLAUDIO:\n",
            "Ay, but the best.\n",
            "\n",
            "MERCUTIO:\n",
            "I am hurt.\n",
            "A plague o' both your houses! They do you good defend,\n",
            "Could time remember my drown'd father. Thou decleciving;\n",
            "Who late I promised\n",
            "The breath to asking a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiD4dJJccNR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}