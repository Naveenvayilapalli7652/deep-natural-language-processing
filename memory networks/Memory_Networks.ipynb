{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Memory Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtxg35PNtyZ3A7bAMAoWPt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/deep-natural-language-processing/blob/master/memory%20networks/Memory_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAQALE_CCZ7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, print_function, unicode_literals, division\n",
        "from builtins import range, input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbpKb3PpYSFK",
        "colab_type": "code",
        "outputId": "18037470-f7d3-4261-fbd1-d0415cb3c344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re \n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "gc.enable()\n",
        "import tarfile\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, Input, Lambda, Reshape, add, dot, Activation \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.utils import get_file\n",
        "import keras.backend as K\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvZaRoPvqkgz",
        "colab_type": "text"
      },
      "source": [
        "### Single Supproting Fact"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvQtSXQSZNYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = get_file('babi-tasks-v1-2.tar.gz',\n",
        "                origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
        "\n",
        "tar = tarfile.open(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD5ROsULZs7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "challenges = {\n",
        "    'single_supporting_fact_10k':'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
        "    'two_supporting_fact_10k':'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGGfk7MTaT1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sent):\n",
        "  return [x.strip() for x in re.split('(\\W+)?',sent) if x.strip()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bta0uyNtamJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stories(f):\n",
        "  data = []\n",
        "  story = []\n",
        "  printed = False\n",
        "  count = 0\n",
        "  for line in f:\n",
        "    count+=1\n",
        "    if count < 5:\n",
        "      print(line)\n",
        "    line = line.decode('utf-8').strip()\n",
        "    nid, line = line.split(' ', 1)\n",
        "    if int(nid) == 1:\n",
        "      story = []\n",
        "    if '\\t' in line:\n",
        "      q, a, supporting = line.split('\\t')\n",
        "      q = tokenize(q)\n",
        "      story_so_far = [[str(i)] + s for i, s in enumerate(story) if s]\n",
        "      data.append((story_so_far, q, a))\n",
        "      story.append('')\n",
        "    else:\n",
        "      story.append(tokenize(line))\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbkFgUm8bvmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def should_flatten(el):\n",
        "  return not isinstance(el, (str, bytes))\n",
        "\n",
        "def flatten(l):\n",
        "  for el in l:\n",
        "    if should_flatten(el):\n",
        "      yield from flatten(el)\n",
        "    else:\n",
        "      yield el"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G49NVvvWcMH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word2idx, story_maxlen, query_maxlen):\n",
        "  inputs, queries, answers = [], [], []\n",
        "  for story, query, answer in data:\n",
        "    inputs.append([[word2idx[w] for w in s] for s in story])\n",
        "    queries.append([word2idx[w] for w in query])\n",
        "    answers.append([word2idx[answer]])\n",
        "  return (\n",
        "    [pad_sequences(x, maxlen=story_maxlen) for x in inputs],\n",
        "    pad_sequences(queries, maxlen=query_maxlen),\n",
        "    np.array(answers)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F2JRWqXerXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stack_inputs(inputs, story_maxsents, story_maxlen):\n",
        "  for i, story in enumerate(inputs):\n",
        "    inputs[i] = np.concatenate(\n",
        "        [\n",
        "         story, \n",
        "         np.zeros((story_maxsents-story.shape[0], story_maxlen),'int')\n",
        "        ]\n",
        "    )\n",
        "  return np.stack(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA0HHRoSfxHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(challenge_type):\n",
        "  challenge = challenges[challenge_type]\n",
        "  \n",
        "  train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
        "  test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
        "  \n",
        "  stories = train_stories + test_stories\n",
        "  \n",
        "  story_maxlen = max((len(s) for x, _, _ in stories for s in x))\n",
        "  story_maxsents = max((len(x) for x, _, _ in stories))\n",
        "  query_maxlen = max(len(x) for _, x, _ in stories)\n",
        "\n",
        "  vocab = sorted(set(flatten(stories)))\n",
        "  vocab.insert(0, '<PAD>')\n",
        "  vocab_size = len(vocab)\n",
        "\n",
        "  word2idx = {c:i for i, c in enumerate(vocab)}\n",
        "\n",
        "  inputs_train, queries_train, answers_train = vectorize_stories(\n",
        "      train_stories,\n",
        "      word2idx,\n",
        "      story_maxlen,\n",
        "      query_maxlen\n",
        "  )\n",
        "  inputs_test, queries_test, answers_test = vectorize_stories(\n",
        "      test_stories, \n",
        "      word2idx,\n",
        "      story_maxlen,\n",
        "      query_maxlen\n",
        "  )\n",
        "  inputs_train = stack_inputs(inputs_train, story_maxsents, story_maxlen)\n",
        "  inputs_test = stack_inputs(inputs_test, story_maxsents, story_maxlen)\n",
        "  print(f\"inputs_train.shape {inputs_train.shape}, inputs_test.shape {inputs_test.shape}\")\n",
        "  return train_stories, test_stories, inputs_train, queries_train, answers_train, \\\n",
        "  inputs_test, queries_test, answers_test, story_maxsents, story_maxlen, query_maxlen, vocab, vocab_size "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQvw8syFiFzF",
        "colab_type": "code",
        "outputId": "5459a452-ccc5-45cd-8a7f-7d2de1b2d998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "train_stories, test_stories, inputs_train, queries_train, answers_train, \\\n",
        "  inputs_test, queries_test, answers_test, story_maxsents, story_maxlen, query_maxlen, vocab, vocab_size = get_data('single_supporting_fact_10k')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'1 Mary moved to the bathroom.\\n'\n",
            "b'2 John went to the hallway.\\n'\n",
            "b'3 Where is Mary? \\tbathroom\\t1\\n'\n",
            "b'4 Daniel went back to the hallway.\\n'\n",
            "b'1 John travelled to the hallway.\\n'\n",
            "b'2 Mary journeyed to the bathroom.\\n'\n",
            "b'3 Where is John? \\thallway\\t1\\n'\n",
            "b'4 Daniel went back to the bathroom.\\n'\n",
            "inputs_train.shape (10000, 10, 8), inputs_test.shape (1000, 10, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyR1p8i3iUtc",
        "colab_type": "code",
        "outputId": "1f52cefb-3961-4884-9c97-91b11268a399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        }
      },
      "source": [
        "embedding_dim = 15\n",
        "\n",
        "input_story_ = Input((story_maxsents, story_maxlen))\n",
        "embedded_story = Embedding(vocab_size, embedding_dim)(input_story_)\n",
        "embedded_story = Lambda(lambda x: K.sum(x, axis=2))(embedded_story)\n",
        "print('input_story_.shape, embedded_story.shape: ', input_story_.shape, embedded_story.shape)\n",
        "\n",
        "\n",
        "input_question_ = Input((query_maxlen, ))\n",
        "embedded_question = Embedding(vocab_size, embedding_dim)(input_question_)\n",
        "embedded_question = Lambda(lambda x: K.sum(x, axis=1))(embedded_question)\n",
        "\n",
        "embedded_question = Reshape((1, embedding_dim))(embedded_question)\n",
        "print('inp_q.shape, emb_q.shape', input_question_.shape, embedded_question.shape)\n",
        "\n",
        "x = dot([embedded_story, embedded_question], 2)\n",
        "x = Reshape((story_maxsents, ))(x)\n",
        "x = Activation('softmax')(x)\n",
        "story_weights = Reshape((story_maxsents, 1))(x)\n",
        "print(\"story_weights.shape\", story_weights.shape)\n",
        "\n",
        "x = dot([story_weights, embedded_story], 1)\n",
        "x = Reshape((embedding_dim, ))(x)\n",
        "ans = Dense(vocab_size, activation='softmax')(x)\n",
        "\n",
        "model = Model([input_story_, input_question_], ans)\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=1e-2),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "r = model.fit([inputs_train, queries_train],\n",
        "              answers_train,\n",
        "              epochs=10,\n",
        "              batch_size=32,\n",
        "              validation_data=([inputs_test, queries_test], answers_test)\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_story_.shape, embedded_story.shape:  (?, 10, 8) (?, 10, 15)\n",
            "inp_q.shape, emb_q.shape (?, 4) (?, 1, 15)\n",
            "story_weights.shape (?, 10, 1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "10000/10000 [==============================] - 9s 879us/step - loss: 0.7462 - acc: 0.7281 - val_loss: 0.0239 - val_acc: 0.9950\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 1s 147us/step - loss: 0.0122 - acc: 0.9962 - val_loss: 1.9996e-04 - val_acc: 1.0000\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 1s 146us/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.0051 - val_acc: 0.9960\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 1s 145us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0037 - val_acc: 0.9990\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 2s 151us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 3.2651e-06 - val_acc: 1.0000\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 1s 150us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 2.9528e-05 - val_acc: 1.0000\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 1s 148us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 1.3819e-05 - val_acc: 1.0000\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 1s 148us/step - loss: 0.0043 - acc: 0.9995 - val_loss: 2.3058e-04 - val_acc: 1.0000\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 1s 147us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 3.1609e-06 - val_acc: 1.0000\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 2s 151us/step - loss: 3.1586e-06 - acc: 1.0000 - val_loss: 3.1608e-06 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeaIAdGkqgDh",
        "colab_type": "text"
      },
      "source": [
        "#### Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33TfsnFOnky1",
        "colab_type": "code",
        "outputId": "2f817ccc-fae6-408a-cc94-2a17448cd96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while True:\n",
        "\n",
        "  debug_model = Model([input_story_, input_question_], story_weights)\n",
        "\n",
        "  story_idx = np.random.choice(len(train_stories))\n",
        "\n",
        "  i = inputs_train[story_idx:story_idx+1]\n",
        "  q = queries_train[story_idx:story_idx+1]\n",
        "  w = debug_model.predict([i,q]).flatten()\n",
        "\n",
        "  story, question, ans = train_stories[story_idx]\n",
        "  print(\"story:\\n\")\n",
        "  for i, line in enumerate(story):\n",
        "    print(\"{:1.5f}\".format(w[i]), \"\\t\", \" \".join(line))\n",
        "  print()\n",
        "  print(\"question: \", \" \".join(question))\n",
        "  print(\"answer: \", ans)\n",
        "\n",
        "  print()\n",
        "  if input(\"Another story.? y/n\") == \"n\":\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "story:\n",
            "\n",
            "0.00000 \t 0 John moved to the bedroom .\n",
            "0.00000 \t 1 Daniel journeyed to the bathroom .\n",
            "0.00000 \t 3 Daniel moved to the hallway .\n",
            "0.00000 \t 4 Sandra journeyed to the garden .\n",
            "0.00010 \t 6 Daniel went back to the bedroom .\n",
            "0.00000 \t 7 Mary moved to the hallway .\n",
            "0.02529 \t 9 Daniel went to the kitchen .\n",
            "0.97460 \t 10 Daniel went back to the hallway .\n",
            "0.00000 \t 12 Sandra went to the bathroom .\n",
            "0.00001 \t 13 Sandra travelled to the bedroom .\n",
            "\n",
            "question:  Where is Daniel ?\n",
            "answer:  hallway\n",
            "\n",
            "Another story.? y/ny\n",
            "story:\n",
            "\n",
            "0.00000 \t 0 Daniel went to the bedroom .\n",
            "0.00000 \t 1 Daniel travelled to the office .\n",
            "0.00000 \t 3 Sandra went to the office .\n",
            "0.00000 \t 4 John travelled to the office .\n",
            "0.00000 \t 6 John travelled to the kitchen .\n",
            "0.00000 \t 7 John journeyed to the office .\n",
            "0.04168 \t 9 Daniel moved to the bathroom .\n",
            "0.95832 \t 10 Daniel moved to the garden .\n",
            "\n",
            "question:  Where is Daniel ?\n",
            "answer:  garden\n",
            "\n",
            "Another story.? y/ny\n",
            "story:\n",
            "\n",
            "0.00000 \t 0 Mary moved to the hallway .\n",
            "0.00000 \t 1 Mary travelled to the bathroom .\n",
            "0.00000 \t 3 Mary went back to the office .\n",
            "0.00000 \t 4 Daniel travelled to the hallway .\n",
            "0.00000 \t 6 Sandra moved to the bedroom .\n",
            "0.00000 \t 7 Mary travelled to the bedroom .\n",
            "0.00000 \t 9 Daniel went back to the bathroom .\n",
            "0.00000 \t 10 Daniel went to the kitchen .\n",
            "0.00000 \t 12 Daniel journeyed to the bathroom .\n",
            "1.00000 \t 13 Mary journeyed to the garden .\n",
            "\n",
            "question:  Where is Mary ?\n",
            "answer:  garden\n",
            "\n",
            "Another story.? y/ny\n",
            "story:\n",
            "\n",
            "0.00000 \t 0 Sandra went to the bedroom .\n",
            "0.00000 \t 1 Mary journeyed to the hallway .\n",
            "0.00000 \t 3 Sandra went back to the bathroom .\n",
            "0.00000 \t 4 Sandra went to the kitchen .\n",
            "0.00124 \t 6 Daniel went back to the kitchen .\n",
            "0.02751 \t 7 Daniel travelled to the bathroom .\n",
            "0.97125 \t 9 Daniel went back to the hallway .\n",
            "0.00000 \t 10 Mary journeyed to the office .\n",
            "\n",
            "question:  Where is Daniel ?\n",
            "answer:  hallway\n",
            "\n",
            "Another story.? y/ny\n",
            "story:\n",
            "\n",
            "0.99855 \t 0 Mary moved to the bathroom .\n",
            "0.00000 \t 1 John went to the garden .\n",
            "\n",
            "question:  Where is Mary ?\n",
            "answer:  bathroom\n",
            "\n",
            "Another story.? y/ny\n",
            "story:\n",
            "\n",
            "0.00953 \t 0 Sandra went back to the garden .\n",
            "0.99046 \t 1 Sandra went to the bedroom .\n",
            "\n",
            "question:  Where is Sandra ?\n",
            "answer:  bedroom\n",
            "\n",
            "Another story.? y/ny\n",
            "story:\n",
            "\n",
            "0.00000 \t 0 Mary went to the bedroom .\n",
            "0.00000 \t 1 Sandra went back to the hallway .\n",
            "0.10075 \t 3 Daniel moved to the hallway .\n",
            "0.89925 \t 4 Daniel journeyed to the bedroom .\n",
            "\n",
            "question:  Where is Daniel ?\n",
            "answer:  bedroom\n",
            "\n",
            "Another story.? y/ny\n",
            "story:\n",
            "\n",
            "0.00000 \t 0 Mary went back to the office .\n",
            "0.00000 \t 1 Daniel moved to the bathroom .\n",
            "0.00000 \t 3 Daniel journeyed to the hallway .\n",
            "0.00000 \t 4 Mary travelled to the hallway .\n",
            "0.00000 \t 6 Mary went to the bathroom .\n",
            "0.99993 \t 7 John journeyed to the office .\n",
            "0.00000 \t 9 Sandra went to the bedroom .\n",
            "0.00007 \t 10 Sandra moved to the hallway .\n",
            "\n",
            "question:  Where is John ?\n",
            "answer:  office\n",
            "\n",
            "Another story.? y/ny\n",
            "story:\n",
            "\n",
            "0.00000 \t 0 Sandra went back to the garden .\n",
            "0.99996 \t 1 Daniel travelled to the bathroom .\n",
            "0.00000 \t 3 Sandra journeyed to the bedroom .\n",
            "0.00004 \t 4 Mary went to the kitchen .\n",
            "\n",
            "question:  Where is Daniel ?\n",
            "answer:  bathroom\n",
            "\n",
            "Another story.? y/nn\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}