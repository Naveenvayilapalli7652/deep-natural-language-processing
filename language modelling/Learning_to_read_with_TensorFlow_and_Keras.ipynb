{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning to read with TensorFlow and Keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlmZyWPAxAZtj4amrzU7Dj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/deep-natural-language-processing/blob/master/language%20modelling/Learning_to_read_with_TensorFlow_and_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6JgXDRVwmjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70e005c8-327e-4993-869d-99dcb649193d"
      },
      "source": [
        "!pip install tf-nightly\n",
        "!pip install tensorflow-addons\n",
        "!pip install keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/f1/39331883a51dc978a36c036e5df707c76ca6a016050f7d08b9685befaf93/tf_nightly-2.2.0.dev20200313-cp36-cp36m-manylinux2010_x86_64.whl (531.4MB)\n",
            "\u001b[K     |████████████████████████████████| 531.4MB 32kB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Collecting astunparse==1.6.3\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.17.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.27.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.1.8)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Collecting tb-nightly<2.3.0a0,>=2.2.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/95/c3403aeb0f3aa60ff8d34d28c7c82c0ce68863cc57a41920726566768839/tb_nightly-2.2.0a20200312-py3-none-any.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 54.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 53.0MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/8a/fc0696ed978443f49e1e91991ebefacb75013491227392d380ac4c3e2dcf/tf_estimator_nightly-2.3.0.dev2020031301-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tf-nightly) (45.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.0.0)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/ec/3da49289b93963bd8b32d29ed108f1809436ff3d9cd4e29c90bac4a7292f/tensorboard_plugin_wit-1.6.0.post2-py3-none-any.whl (775kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, astunparse, tensorboard-plugin-wit, tb-nightly, h5py, tf-estimator-nightly, tf-nightly\n",
            "  Found existing installation: gast 0.2.2\n",
            "    Uninstalling gast-0.2.2:\n",
            "      Successfully uninstalled gast-0.2.2\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "Successfully installed astunparse-1.6.3 gast-0.3.3 h5py-2.10.0 tb-nightly-2.2.0a20200312 tensorboard-plugin-wit-1.6.0.post2 tf-estimator-nightly-2.3.0.dev2020031301 tf-nightly-2.2.0.dev20200313\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/f7/98c461ab7fcb4828f66a702f1af76811b9d3f47d62816f8cc57a9461b0da/tensorflow_addons-0.8.3-cp36-cp36m-manylinux2010_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 40.3MB/s \n",
            "\u001b[?25hCollecting typeguard\n",
            "  Downloading https://files.pythonhosted.org/packages/06/37/d236aec27f8a8eed66f1a17116eb51684528cf8005a6883f879fe2e842ae/typeguard-2.7.1-py3-none-any.whl\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.8.3 typeguard-2.7.1\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.17.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.6)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.14.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=31b6800c7a477069a8c53ae80a9ef290f3b148f67a80bad5f4f23b919ca5c941\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=d0311f8d9792ae3891a7acded71f0c4a1882e2065f746b576dea98abcc16938d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.3 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zd_4-cVw3Ld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "f58b82f4-229d-4ea5-dcc3-63b8da8ac880"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "print(tf.__version__)\n",
        "dir(tfa.seq2seq)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-dev20200313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AttentionMechanism',\n",
              " 'AttentionWrapper',\n",
              " 'AttentionWrapperState',\n",
              " 'BahdanauAttention',\n",
              " 'BahdanauMonotonicAttention',\n",
              " 'BaseDecoder',\n",
              " 'BasicDecoder',\n",
              " 'BasicDecoderOutput',\n",
              " 'BeamSearchDecoder',\n",
              " 'BeamSearchDecoderOutput',\n",
              " 'BeamSearchDecoderState',\n",
              " 'CustomSampler',\n",
              " 'Decoder',\n",
              " 'FinalBeamSearchDecoderOutput',\n",
              " 'GreedyEmbeddingSampler',\n",
              " 'InferenceSampler',\n",
              " 'LuongAttention',\n",
              " 'LuongMonotonicAttention',\n",
              " 'SampleEmbeddingSampler',\n",
              " 'Sampler',\n",
              " 'ScheduledEmbeddingTrainingSampler',\n",
              " 'ScheduledOutputTrainingSampler',\n",
              " 'SequenceLoss',\n",
              " 'TrainingSampler',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " 'attention_wrapper',\n",
              " 'basic_decoder',\n",
              " 'beam_search_decoder',\n",
              " 'decoder',\n",
              " 'dynamic_decode',\n",
              " 'gather_tree',\n",
              " 'gather_tree_from_array',\n",
              " 'hardmax',\n",
              " 'loss',\n",
              " 'monotonic_attention',\n",
              " 'safe_cumprod',\n",
              " 'sampler',\n",
              " 'sequence_loss',\n",
              " 'tile_batch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_KwGSLsxOIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e648656c-f2ac-4ade-bef1-68b8c1cfa3ce"
      },
      "source": [
        "!wget http://www.thespermwhale.com/jaseweston/babi/CBTest.tgz\n",
        "!tar -xf CBTest.tgz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-13 12:01:46--  http://www.thespermwhale.com/jaseweston/babi/CBTest.tgz\n",
            "Resolving www.thespermwhale.com (www.thespermwhale.com)... 69.65.3.213\n",
            "Connecting to www.thespermwhale.com (www.thespermwhale.com)|69.65.3.213|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120547669 (115M) [application/x-tar]\n",
            "Saving to: ‘CBTest.tgz’\n",
            "\n",
            "CBTest.tgz          100%[===================>] 114.96M  11.2MB/s    in 12s     \n",
            "\n",
            "2020-03-13 12:01:58 (9.92 MB/s) - ‘CBTest.tgz’ saved [120547669/120547669]\n",
            "\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
            "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku5hVwiTxPje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "e297e90a-6f80-4e81-cd62-d2e049920d5a"
      },
      "source": [
        "!ls CBTest/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cbtest_CN_test_2500ex.txt   cbtest_P_valid_2000ex.txt\n",
            "cbtest_CN_train.txt\t    cbtest_V_test_2500ex.txt\n",
            "cbtest_CN_valid_2000ex.txt  cbtest_V_train.txt\n",
            "cbtest_NE_test_2500ex.txt   cbtest_V_valid_2000ex.txt\n",
            "cbtest_NE_train.txt\t    cbt_test.txt\n",
            "cbtest_NE_valid_2000ex.txt  cbt_train.txt\n",
            "cbtest_P_test_2500ex.txt    cbt_valid.txt\n",
            "cbtest_P_train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFVaG19jxQnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "475081a2-d87d-4ce2-8471-698f2dcb0065"
      },
      "source": [
        "lines = tf.data.TextLineDataset('CBTest/data/cbt_train.txt')\n",
        "for row in lines.take(3):\n",
        "  print(row)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'_BOOK_TITLE_ : Andrew_Lang___Prince_Prigio.txt.out', shape=(), dtype=string)\n",
            "tf.Tensor(b'CHAPTER I. -LCB- Chapter heading picture : p1.jpg -RCB- How the Fairies were not Invited to Court .', shape=(), dtype=string)\n",
            "tf.Tensor(b'Once upon a time there reigned in Pantouflia a king and a queen .', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LBw37Q8xrbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "53e4dd2c-3e60-4059-ecae-ee867667e4b8"
      },
      "source": [
        "lines  = lines.filter(\n",
        "    lambda x: not tf.strings.regex_full_match(x, \"_BOOK_TITLE_.*\")\n",
        ")\n",
        "\n",
        "punctuation = r'[!\"#$%&()\\*\\+,-\\./:;<=>?@\\[\\\\\\]^_`{|}~\\']'\n",
        "\n",
        "lines = lines.map(lambda x: tf.strings.regex_replace(x, punctuation, ' '))\n",
        "\n",
        "for row in lines.take(3):\n",
        "  print(row)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'CHAPTER I   LCB  Chapter heading picture   p1 jpg  RCB  How the Fairies were not Invited to Court  ', shape=(), dtype=string)\n",
            "tf.Tensor(b'Once upon a time there reigned in Pantouflia a king and a queen  ', shape=(), dtype=string)\n",
            "tf.Tensor(b'With almost everything else to make them happy   they wanted one thing   they had no children  ', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2u9FhuwyRL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "1bf881c2-c5df-457e-f3a2-027eeadeab94"
      },
      "source": [
        "words = lines.map(tf.strings.split)\n",
        "wordsets = words.unbatch().batch(11)\n",
        "for row in wordsets.take(3):\n",
        "  print(row)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'CHAPTER' b'I' b'LCB' b'Chapter' b'heading' b'picture' b'p1' b'jpg'\n",
            " b'RCB' b'How' b'the'], shape=(11,), dtype=string)\n",
            "tf.Tensor(\n",
            "[b'Fairies' b'were' b'not' b'Invited' b'to' b'Court' b'Once' b'upon' b'a'\n",
            " b'time' b'there'], shape=(11,), dtype=string)\n",
            "tf.Tensor(\n",
            "[b'reigned' b'in' b'Pantouflia' b'a' b'king' b'and' b'a' b'queen' b'With'\n",
            " b'almost' b'everything'], shape=(11,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6o4GViAyoMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "922290ca-a948-480e-ec94-cc24a3522dc2"
      },
      "source": [
        "def get_example_label(row):\n",
        "  example = tf.strings.reduce_join(row[:-1], separator = ' ')\n",
        "  example = tf.expand_dims(example, axis=0)\n",
        "  label = row[-1:]\n",
        "  return example, label\n",
        "\n",
        "data = wordsets.map(get_example_label)\n",
        "data = data.shuffle(1000)\n",
        "for row in data.take(3):\n",
        "  print(row)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
            "array([b'hoping that either the Firedrake would roast Prince Prigio alive'],\n",
            "      dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'LRB'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'and when the queen looked up lo and behold on'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'every'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'of our aunts No the old cats replied the queen'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'for'], dtype=object)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8faazVGzUyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 10000\n",
        "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_sequence_length=10\n",
        ")\n",
        "\n",
        "vectorize_layer.adapt(lines.batch(64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN17PSGW0Cjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a21cdd2-7e35-4341-c266-052acc10cb7c"
      },
      "source": [
        "vectorize_layer.get_vocabulary()[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'the', b'and', b'to', b'a', b'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-VOEJ3t01W2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d0188bb-be58-4179-b364-8a218bcb9840"
      },
      "source": [
        "vectorize_layer.get_vocabulary()[-5:]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'custard', b'curtained', b'cupboards', b'culture', b'cuckoo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voN096X007Sg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "24d35ddd-9fb6-489d-9581-6720a3893303"
      },
      "source": [
        "for batch in data.batch(3).take(1):\n",
        "  print(batch[0])\n",
        "  print(vectorize_layer(batch[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[b'determined to challenge the gentleman who was in the carriage']\n",
            " [b'in the valley where it was not so very cold']\n",
            " [b'bottom of the hill and shouted Hi Well grunted the']], shape=(3, 1), dtype=string)\n",
            "tf.Tensor(\n",
            "[[1288    4 7937    2  789   60    9   11    2 1693]\n",
            " [  11    2  884   95   10    9   29   32   56  423]\n",
            " [1083    6    2  451    3 1006 3701   85 5301    2]], shape=(3, 10), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acbLaemG1S86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderDecoder(tf.keras.Model):\n",
        "  def __init__(self, max_features=5000, embedding_dims = 200, rnn_units=1024):\n",
        "    super().__init__()\n",
        "    self.max_features = max_features\n",
        "    \n",
        "    self.vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "        max_tokens=max_features,\n",
        "        output_sequence_length=10\n",
        "    )\n",
        "    \n",
        "    self.encoder_embedding = tf.keras.layers.Embedding(max_features+1, embedding_dims)\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(rnn_units, return_state=True)\n",
        "\n",
        "    self.decoder_embedding = tf.keras.layers.Embedding(max_features+1, embedding_dims)\n",
        "    sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "    decoder_cell = tf.keras.layers.LSTMCell(rnn_units)\n",
        "    projection_layer = tf.keras.layers.Dense(max_features)\n",
        "    self.decoder = tfa.seq2seq.BasicDecoder(decoder_cell, sampler, projection_layer)\n",
        "    self.attention = tf.keras.layers.Attention()\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data[0], data[1]\n",
        "    x = self.vectorize_layer(x)\n",
        "    y = self.vectorize_layer(y)[:, 0:1]\n",
        "    y_one_hot = tf.one_hot(y, self.max_features)\n",
        "    with tf.GradientTape() as tape:\n",
        "      embedded_inputs = self.encoder_embedding(x)\n",
        "      encoder_outputs, state_h, state_c = self.lstm_layer(embedded_inputs)\n",
        "      attn_output = self.attention([encoder_outputs, state_h])\n",
        "      attn_output = tf.expand_dims(attn_output, axis=1)\n",
        "      targets = self.decoder_embedding(tf.zeros_like(y))\n",
        "      concat_output = tf.concat([targets, attn_output], axis=-1)\n",
        "      outputs, _, _ = self.decoder(concat_output, initial_state=[state_h, state_c])\n",
        "\n",
        "      y_pred = outputs.rnn_output\n",
        "\n",
        "      loss = self.compiled_loss(\n",
        "          y_one_hot, \n",
        "          y_pred,\n",
        "          regularization_losses = self.losses\n",
        "      )\n",
        "      trainable_variables = self.trainable_variables\n",
        "      gradients = tape.gradient(loss, trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "      self.compiled_metrics.update_state(y_one_hot, y_pred)\n",
        "      return {m.name:m.result() for m in self.metrics}\n",
        "    \n",
        "  def predict_step(self, data, select_from_top_n=1):\n",
        "    x = data\n",
        "    if isinstance(x, tuple) and len(x) == 2:\n",
        "      x = x[0]\n",
        "    x = self.vectorize_layer(x)\n",
        "    embedded_inputs = self.encoder_embedding(x)\n",
        "    encoder_outputs, state_h, state_c = self.lstm_layer(embedded_inputs)\n",
        "    attn_output = self.attention([encoder_outputs, state_h])\n",
        "    attn_output = tf.expand_dims(attn_output, axis=1)\n",
        "    \n",
        "    targets = self.decoder_embedding(tf.zeros_like(x[:, -1:]))\n",
        "    concat_output = tf.concat([targets, attn_output], axis=-1)\n",
        "    outputs, _, _ = self.decoder(\n",
        "        concat_output, initial_state=[state_h, state_c])\n",
        "    \n",
        "    y_pred = tf.squeeze(outputs.rnn_output, axis=1)\n",
        "    top_n = tf.argsort(\n",
        "        y_pred[:, 2:], axis=1, direction='DESCENDING')[: ,:select_from_top_n]\n",
        "    chosen_indices = tf.random.uniform(\n",
        "        [top_n.shape[0], 1], minval=0, maxval=select_from_top_n, \n",
        "        dtype=tf.dtypes.int32)\n",
        "    counter = tf.expand_dims(tf.range(0, top_n.shape[0]), axis=1)\n",
        "    indices = tf.concat([counter, chosen_indices], axis=1)\n",
        "    choices = tf.gather_nd(top_n, indices)\n",
        "    words = [self.vectorize_layer.get_vocabulary()[i] for i in choices]\n",
        "    return words\n",
        "\n",
        "  def predict(self, starting_string, num_steps=50, select_from_top_n=1):\n",
        "    s = tf.compat.as_bytes(starting_string).split(b' ')\n",
        "    for _ in range(num_steps):\n",
        "      windowed = [b' '.join(s[-10:])]\n",
        "      pred = self.predict_step([windowed], select_from_top_n=select_from_top_n)\n",
        "      s.append(pred[0])\n",
        "    return b' '.join(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2-LooDp5N8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = EncoderDecoder()\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy'])\n",
        "model.vectorize_layer.adapt(lines.batch(256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLBwww8J5RI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "f5b1dba6-c9bd-4f18-e7c0-4c9f6f2e2ee1"
      },
      "source": [
        "model.fit(data.batch(256), epochs=30, callbacks=[tf.keras.callbacks.ModelCheckpoint('text_gen_ckpt')])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1690/1690 [==============================] - 122s 72ms/step - loss: 5.4021 - accuracy: 0.1295\n",
            "Epoch 2/30\n",
            "1690/1690 [==============================] - 125s 74ms/step - loss: 4.7577 - accuracy: 0.1699\n",
            "Epoch 3/30\n",
            "1690/1690 [==============================] - 124s 74ms/step - loss: 4.3987 - accuracy: 0.1892\n",
            "Epoch 4/30\n",
            "1690/1690 [==============================] - 124s 74ms/step - loss: 3.9583 - accuracy: 0.2188\n",
            "Epoch 5/30\n",
            "1690/1690 [==============================] - 124s 74ms/step - loss: 3.3707 - accuracy: 0.2809\n",
            "Epoch 6/30\n",
            "1690/1690 [==============================] - 124s 74ms/step - loss: 2.7337 - accuracy: 0.3831\n",
            "Epoch 7/30\n",
            "1690/1690 [==============================] - 124s 74ms/step - loss: 2.1562 - accuracy: 0.4970\n",
            "Epoch 8/30\n",
            "1690/1690 [==============================] - 125s 74ms/step - loss: 1.6845 - accuracy: 0.5996\n",
            "Epoch 9/30\n",
            "1690/1690 [==============================] - 125s 74ms/step - loss: 1.3354 - accuracy: 0.6769\n",
            "Epoch 10/30\n",
            "1690/1690 [==============================] - 125s 74ms/step - loss: 1.0990 - accuracy: 0.7274\n",
            "Epoch 11/30\n",
            "1690/1690 [==============================] - 125s 74ms/step - loss: 0.9334 - accuracy: 0.7627\n",
            "Epoch 12/30\n",
            "1690/1690 [==============================] - 125s 74ms/step - loss: 0.8218 - accuracy: 0.7857\n",
            "Epoch 13/30\n",
            "1690/1690 [==============================] - 125s 74ms/step - loss: 0.7371 - accuracy: 0.8053\n",
            "Epoch 14/30\n",
            "1690/1690 [==============================] - 124s 73ms/step - loss: 0.6780 - accuracy: 0.8169\n",
            "Epoch 15/30\n",
            "1690/1690 [==============================] - 124s 73ms/step - loss: 0.6241 - accuracy: 0.8296\n",
            "Epoch 16/30\n",
            " 586/1690 [=========>....................] - ETA: 1:18 - loss: 0.6152 - accuracy: 0.8293"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-dbc59de77dce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text_gen_ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    782\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHGHlMgG5VMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "29a13825-8006-4b28-a6c0-d8cd152092ca"
      },
      "source": [
        "model.fit(data.batch(256), epochs=10, callbacks=[tf.keras.callbacks.ModelCheckpoint('text_gen_ckpt')])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "    285/Unknown - 20s 71ms/step - loss: 1.0169 - accuracy: 0.7432"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1891e4e3c9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text_gen_ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    782\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHEpuKTe5ZHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d220615d-4fa0-4d9d-d8e2-f21db419a1f8"
      },
      "source": [
        "model.load_weights('text_gen_ckpt')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f39f4b7b588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpdjEDza5a8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "bf0839e0-e686-4b51-b6e4-47ab5121de94"
      },
      "source": [
        "print(model.predict('The mouse and the rabbit went in together'))\n",
        "\n",
        "print(model.predict('Once upon a time there was a Queen named Darling'))\n",
        "\n",
        "print(model.predict('In a city far from here the teacup shook upon the table'))\n",
        "\n",
        "print(model.predict('It was a strange and quiet theater and the people watched from home'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'The mouse and the rabbit went in together and and from the first time he felt that he could n t see any one in the green forest indeed what is it asked sammy pretending to look out of the doorway yes sir it was he he cried it is all the best of you know tell these'\n",
            "b'Once upon a time there was a Queen named Darling alive in a certain voice he learned it out before it with his sharp teeth and with a little noise of tail the water was soft and this was her long cry grandfather frog had grown there no longer there was such a thing as mrs quack came into the'\n",
            "b'In a city far from here the teacup shook upon the table which were on their side it had been the most beautiful old appetite but farmer brown s boy would n t eat him until he was a prisoner or two not at all i do n t think so i can do just what i do n t know who'\n",
            "b'It was a strange and quiet theater and the people watched from home toward last was it the very best thing to be is to know what was going on about him then peter rabbit came to see what to see her so he walked with the hunters of the little round doorway and in the green forest unc billy possum had been'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8MLaPHS5eNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8b28c034-b0c3-4522-a6fa-261da7b8fcdf"
      },
      "source": [
        "import kerastuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "  model = EncoderDecoder(\n",
        "      rnn_units=hp.Int('units', min_value=256, max_value=1200, step=256))\n",
        "  \n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', values=[1e-3, 1e-4, 3e-4])),\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),                 \n",
        "      metrics=['accuracy'])\n",
        "  \n",
        "  model.vectorize_layer.adapt(lines.batch(256))\n",
        "  return model\n",
        "\n",
        "tuner = kt.tuners.RandomSearch(\n",
        "    build_model,\n",
        "    objective='accuracy',\n",
        "    max_trials=15,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='text_generation')\n",
        "\n",
        "tuner.search(\n",
        "    data.batch(256), \n",
        "    epochs=10, \n",
        "    callbacks=[tf.keras.callbacks.ModelCheckpoint('text_gen_ckpt')])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "    718/Unknown - 55s 76ms/step - loss: 6.1330 - accuracy: 0.0669"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3w_ZGdj59PJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}